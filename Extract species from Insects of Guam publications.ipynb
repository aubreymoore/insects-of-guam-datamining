{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Run with Python 3 kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions (called by other functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_images_vertically(img1, img2):\n",
    "    \"\"\"\n",
    "    Glues 2 images together with img2 below img1.\n",
    "    Returns the new compound image.\n",
    "    \"\"\"\n",
    "    \n",
    "    import numpy as np\n",
    "    \n",
    "    h1, w1 = img1.shape\n",
    "    h2, w2 = img2.shape\n",
    "\n",
    "    # Create an array big enough to hold img2 below img1.\n",
    "    img = np.zeros(((h1 + h2), max(w1, w2)), np.float32)\n",
    "\n",
    "    # Paste img1 at y=0, x=0\n",
    "    img[0:img1.shape[0], 0:img1.shape[1]] = img1\n",
    "\n",
    "    # Paste img2 at y=h1, x=0\n",
    "    img[h1:h1+img2.shape[0],0:img2.shape[1]] = img2    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_bishop_bulletins_page(bulletin):\n",
    "    \"\"\"\n",
    "    Scrapes data from the Bishop Museum pubs online web page. \n",
    "    Bulletin is b172 for Insects of Guam I and b189 for Insects of Guam II.\n",
    "    A directory named b172 or b189 is created and populated with a CSV file, named b189.csv, containing\n",
    "    titles, stubs, authors, and urls for pdfs.\n",
    "    If the bulletin directory already exists, this function does nothing.\n",
    "    \"\"\"\n",
    "    import requests\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    from bs4 import BeautifulSoup\n",
    "    from urllib.parse import urljoin\n",
    "    from slugify import slugify\n",
    "    \n",
    "    if bulletin not in ['b172', 'b189']:\n",
    "        print(\"bulletin not in ['b172', 'b189']\")\n",
    "        return\n",
    "\n",
    "    bulletins_url = 'http://hbs.bishopmuseum.org/pubs-online/bpbm-bulletins.html'\n",
    "    result = requests.get(bulletins_url)\n",
    "    soup = BeautifulSoup(result.content, features = \"lxml\")\n",
    "\n",
    "    pdf_list = []\n",
    "    links = soup.find_all('a')\n",
    "    for link in links:\n",
    "        if bulletin in link.get('href'):\n",
    "            text = link.previous_sibling.previous_sibling.previous_sibling\n",
    "            parts = text.split(', by ')\n",
    "            if len(parts) == 2:\n",
    "                title = parts[0].strip()\n",
    "                slug = slugify(title)\n",
    "                authors = parts[1].replace('[','').strip()          \n",
    "                url = link.get('href')\n",
    "                url = urljoin(bulletins_url, url)\n",
    "                pdf_list.append({'title':title, 'slug':slug, 'authors':authors, 'url':url})\n",
    "    \n",
    "    df_pdf_list = pd.DataFrame(pdf_list)\n",
    "    os.mkdir(bulletin)\n",
    "    outfile = '{}/{}.csv'.format(bulletin, bulletin)\n",
    "    df_pdf_list.to_csv(outfile, index=False)\n",
    "    \n",
    "    return\n",
    "\n",
    "## Usage example:\n",
    "#scrape_bishop_bulletins_page('b172')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import docker\n",
    "\n",
    "client = docker.from_env()\n",
    "\n",
    "for container in client.containers.list():\n",
    "    container.stop()\n",
    "\n",
    "data = container = client.containers.run('cvat', detach=True)\n",
    "print(data)\n",
    "file_json = data.get_archive('testdump.xml')\n",
    "stream, stat = file_json\n",
    "file_obj = BytesIO()\n",
    "for i in stream:\n",
    "    file_obj.write(i)\n",
    "file_obj.seek(0)\n",
    "tar = tarfile.open(mode='r', fileobj=file_obj)\n",
    "text = tar.extractfile('out.json')\n",
    "q = text.read()\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_file_structure(bulletin):\n",
    "    \"\"\"\n",
    "    bulletin is 'b172' for Insects of Guam I and 'b189' for Insects of Guam II.\n",
    "    Depends on scrape_bishop_bulletins_page\n",
    "    Creates a data file structure in this format:\n",
    "    \n",
    "    b172\n",
    "        anthribidae-of-guam\n",
    "            anthribidae-of-guam.pdf\n",
    "            anthribidae-of-guam-0.jpg\n",
    "            anthribidae-of-guam-1.jpg\n",
    "            ...\n",
    "        formicidae-of-guam\n",
    "            formicidae-of-guam.pdf\n",
    "            formicidae-of-guam-0.jpg\n",
    "            formicidae-of-guam-1.jpg\n",
    "            ...\n",
    "            \n",
    "    Each directory contains a PDF file and a JPG image for each page in the PDF.\n",
    "    \n",
    "    \"\"\"\n",
    "    import requests\n",
    "    import os\n",
    "    import subprocess\n",
    "    import pandas as pd\n",
    "    \n",
    "    if bulletin not in ['b172', 'b189']:\n",
    "        print(\"bulletin not in ['b172', 'b189']\")\n",
    "        return\n",
    "    \n",
    "    if not os.path.exists(bulletin):\n",
    "        print('{} directory does not exist.'.format(bulletin))\n",
    "        print('Scraping Bishop Museum Bulletins web page.')\n",
    "        scrape_bishop_bulletins_page(bulletin)\n",
    "    \n",
    "    pdf_list = pd.read_csv('{}/{}.csv'.format(bulletin, bulletin)).to_dict('records')\n",
    "    \n",
    "    os.chdir('b172'); print(os.getcwd())\n",
    "    for d in pdf_list:\n",
    "        slug = d['slug']\n",
    "        if os.path.exists(slug):\n",
    "            print('{} directory already exists.'.format(slug))\n",
    "            continue\n",
    "\n",
    "        # Create a new directory and move into it\n",
    "        url = d['url']\n",
    "        os.mkdir(slug); os.chdir(slug); print(os.getcwd())\n",
    "\n",
    "        # Download PDF\n",
    "        filename = '{}.pdf'.format(slug)\n",
    "        r = requests.get(url)\n",
    "        open(filename, 'wb').write(r.content)\n",
    "\n",
    "        # Create a JPG image for each page in PDF using the Linux convert command\n",
    "        jpg = filename.replace('pdf', 'jpg')\n",
    "        subprocess.call(['convert', '-density', '200x200', filename, jpg])\n",
    "\n",
    "        # Move up one directory\n",
    "        os.chdir('..'); print(os.getcwd())\n",
    "    os.chdir('..'); print(os.getcwd())\n",
    "    return\n",
    "\n",
    "#create_file_structure('b172')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bounding_box_table(bulletin, section):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    from bs4 import BeautifulSoup\n",
    "    import pandas as pd\n",
    "\n",
    "    xml_file_path = '{}/{}/{}.xml'.format(bulletin, section, section)\n",
    "    f = open(xml_file_path, 'r')\n",
    "    contents = f.read()\n",
    "    soup = BeautifulSoup(contents, features = \"lxml\")\n",
    "\n",
    "    bb_list = []\n",
    "    n = -1\n",
    "    for image in soup.find_all('image'):\n",
    "        for box in image.find_all('box'):\n",
    "            n += 1\n",
    "            species_name = box.text.replace('\\n','')\n",
    "            bb_list.append({\n",
    "                'species_name':species_name, \n",
    "                'page_image':image['name'],\n",
    "                'bb_image': '{}-{}.jpg'.format(species_name.replace(' ', '-'), n),\n",
    "                'xtl':int(float(box['xtl'])),\n",
    "                'ytl':int(float(box['ytl'])),\n",
    "                'xbr':int(float(box['xbr'])),\n",
    "                'ybr':int(float(box['ybr']))\n",
    "            })\n",
    "    df_bb_list = pd.DataFrame(bb_list)\n",
    "    outfile = '{}/{}/bounding_boxes.csv'.format(bulletin, section)\n",
    "    df_bb_list.to_csv(outfile, index=False)\n",
    "    return\n",
    "\n",
    "#make_bounding_box_table('b172', 'barkbeetles-of-guam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_bounding_box_images(bulletin, section):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    import cv2\n",
    "    import os\n",
    "    \n",
    "    bb_list_csv_path = '{}/{}/bounding_boxes.csv'.format(bulletin, section)  \n",
    "    df_bb_list = pd.read_csv(bb_list_csv_path)\n",
    "\n",
    "    mydir = '{}/{}/bounding_box_images'.format(bulletin, section)\n",
    "    if not os.path.exists(mydir):\n",
    "        os.mkdir(mydir)\n",
    "\n",
    "    # Extract bounding box images\n",
    "    for i, r in df_bb_list.iterrows():\n",
    "        page_image_path = '{}/{}/{}'.format(bulletin, section, r.page_image)\n",
    "        im = cv2.imread(page_image_path)\n",
    "        roi = im[r.ytl:r.ybr, r.xtl:r.xbr]\n",
    "        roi_filename = '{}/{}'.format(mydir, r.bb_image)\n",
    "        print(roi_filename)    \n",
    "        cv2.imwrite(roi_filename, roi)\n",
    "    return\n",
    "\n",
    "#extract_bounding_box_images('b172', 'barkbeetles-of-guam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_bounding_box_images(bulletin, section):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import pandasql as ps\n",
    "    import cv2\n",
    "    import numpy as np\n",
    "\n",
    "    \n",
    "    bb_list_csv_path = '{}/{}/bounding_boxes.csv'.format(bulletin, section)  \n",
    "    df_bb_list = pd.read_csv(bb_list_csv_path)\n",
    "\n",
    "    mydir = '{}/{}/bounding_box_images'.format(bulletin, section)\n",
    "\n",
    "    merged_image_dir = '{}/{}/merged_images'.format(bulletin, section)\n",
    "    if not os.path.exists(merged_image_dir):\n",
    "        os.mkdir(merged_image_dir)\n",
    "\n",
    "    sql = '''select species_name \n",
    "    from df_bb_list \n",
    "    group by species_name \n",
    "    order by species_name'''\n",
    "    species_names = ps.sqldf(sql)\n",
    "    \n",
    "    print('species_names: {}'.format(species_names))\n",
    "    \n",
    "    for species_name in species_names.values:\n",
    "        species_name = species_name[0]\n",
    "        print(species_name)\n",
    "        sql = '''select bb_image \n",
    "        from df_bb_list \n",
    "        where species_name=\"{}\" \n",
    "        order by bb_image'''.format(species_name)\n",
    "        df = ps.sqldf(sql)\n",
    "        print(df)\n",
    "        print()\n",
    "\n",
    "        rowcount = df.shape[0]\n",
    "        print('rowcount: {}'.format(rowcount))\n",
    "        if rowcount > 2:\n",
    "            print('More than 2 images to be merged. Not implemented. Continuiing.')\n",
    "            continue\n",
    "        if rowcount == 1:\n",
    "            f = '{}/{}'.format(mydir, df.bb_image[0])\n",
    "            print('f: {}'.format(f))\n",
    "            img = cv2.imread(f, 0)\n",
    "            #cv2.imshow('caca',img)\n",
    "        if rowcount == 2:\n",
    "            f = '{}/{}'.format(mydir, df.bb_image[0])\n",
    "            print('f: {}'.format(f))\n",
    "            img1 = cv2.imread(f, 0)\n",
    "            print(img1)\n",
    "            \n",
    "            f = '{}/{}'.format(mydir, df.bb_image[1])\n",
    "            print('f: {}'.format(f))\n",
    "            img2 = cv2.imread(f, 0)  \n",
    "            #print('img1 shape: {}'.format(img1.shp))\n",
    "            #print('img2 shape: {}'.format(img2.shp))\n",
    "            img = combine_images_vertically(img1, img2)\n",
    "        f = '{}/{}.jpg'.format(merged_image_dir, species_name)\n",
    "        cv2.imwrite(f, img)\n",
    "    return\n",
    "    \n",
    "#merge_bounding_box_images('b172', 'barkbeetles-of-guam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mturk_data_csv(bulletin, section):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    import glob\n",
    "    import pytesseract\n",
    "\n",
    "    try:\n",
    "        from PIL import Image\n",
    "    except ImportError:\n",
    "        import Image\n",
    "\n",
    "    prefix = 'https://github.com/aubreymoore/insects-of-guam-datamining/raw/master'\n",
    "\n",
    "    imagefiles = glob.glob('{}/{}/merged_images/*.jpg'.format(bulletin, section))\n",
    "    outfile = '{}/{}/mturk_data.csv'.format(bulletin, section)\n",
    "\n",
    "    with open(outfile, 'w+') as out:\n",
    "        out.write('image_url,text\\n')\n",
    "        for imagefile in imagefiles:\n",
    "            image_url = '{}/{}'.format(prefix, imagefile)\n",
    "\n",
    "            # Perform optical character recognition on the image\n",
    "            #text = pytesseract.image_to_string(Image.open(fn)).encode('utf-8')    \n",
    "\n",
    "            print('performing optical character recognition on {}'.format(imagefile))\n",
    "            text = pytesseract.image_to_string(Image.open(imagefile))\n",
    "\n",
    "            # Remove double quotes and replace line feeds with <br>\n",
    "            text = text.replace('\\n\\n', '\\n')\n",
    "            text = text.replace('\"', '').replace('\\n', '<br>')\n",
    "\n",
    "            # Separate collection records into individual lines of text\n",
    "            text = text.replace(';', '<br>')\n",
    "\n",
    "            # write record\n",
    "            out.write('{},\"{}\"\\n'.format(image_url, text))  \n",
    "            \n",
    "    return\n",
    "\n",
    "#make_mturk_data_csv('b172', 'barkbeetles-of-guam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aubrey/insects-of-guam-test/b172\n",
      "dragonflies-of-guam directory already exists.\n",
      "thrips-of-guam directory already exists.\n",
      "cercopidae-of-guam directory already exists.\n",
      "membracidae-of-guam directory already exists.\n",
      "psyllidae-from-guam directory already exists.\n",
      "aphidae-and-aleurodidae-of-guam directory already exists.\n",
      "neuropteroid-insects-from-guam directory already exists.\n",
      "butterflies-of-guam directory already exists.\n",
      "sphingidae-of-guam directory already exists.\n",
      "staphylinidae-of-guam directory already exists.\n",
      "rhipiceridae-of-guam directory already exists.\n",
      "ciidae-of-guam directory already exists.\n",
      "elaterid-and-eucnemid-beetles-of-guam directory already exists.\n",
      "coleoptera-heteromera-from-guam directory already exists.\n",
      "new-longicorn-beetles-from-guam-cerambycidae directory already exists.\n",
      "anthribidae-of-guam directory already exists.\n",
      "curculionidae-of-guam directory already exists.\n",
      "barkbeetles-of-guam directory already exists.\n",
      "miscellaneous-families-of-guam-coleoptera directory already exists.\n",
      "stylopidae-of-guam directory already exists.\n",
      "formicidae-of-guam directory already exists.\n",
      "wasps-of-guam directory already exists.\n",
      "bees-of-guam directory already exists.\n",
      "halictine-bees-from-rota-island directory already exists.\n",
      "tipulidae-of-guam directory already exists.\n",
      "culicidae-of-guam directory already exists.\n",
      "trypetidae-otitidae-helomyzidae-and-clusiidae-of-guam-diptera directory already exists.\n",
      "/home/aubrey/insects-of-guam-test\n"
     ]
    }
   ],
   "source": [
    "bulletin = 'b172'\n",
    "create_file_structure(bulletin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point the directory structure should look something like this:\n",
    "\n",
    "    b172\n",
    "        anthribidae-of-guam\n",
    "            anthribidae-of-guam.pdf\n",
    "            anthribidae-of-guam-0.jpg\n",
    "            anthribidae-of-guam-1.jpg\n",
    "            ...\n",
    "        formicidae-of-guam\n",
    "            formicidae-of-guam.pdf\n",
    "            formicidae-of-guam-0.jpg\n",
    "            formicidae-of-guam-1.jpg\n",
    "            ...\n",
    "            \n",
    "The PDF contains the whole section.\n",
    "There is JPG file for each page in the section.\n",
    "\n",
    "The next step is to use CVAT to record coordinates of bounding boxes which determine the position of species\n",
    "sections in the JPGs.  The resulting XML file can be downloaded into the section directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dragonflies-of-guam\n",
      "bb_xml_path_exists: False\n",
      "bb_csv_path_exists: False\n",
      "\n",
      "thrips-of-guam\n",
      "bb_xml_path_exists: False\n",
      "bb_csv_path_exists: False\n",
      "\n",
      "cercopidae-of-guam\n",
      "bb_xml_path_exists: False\n",
      "bb_csv_path_exists: False\n",
      "\n",
      "membracidae-of-guam\n",
      "bb_xml_path_exists: False\n",
      "bb_csv_path_exists: False\n",
      "\n",
      "psyllidae-from-guam\n",
      "bb_xml_path_exists: False\n",
      "bb_csv_path_exists: False\n",
      "\n",
      "aphidae-and-aleurodidae-of-guam\n",
      "bb_xml_path_exists: True\n",
      "bb_csv_path_exists: False\n",
      "Making bb table for aphidae-and-aleurodidae-of-guam\n",
      "Extracting bounding box images.\n",
      "b172/aphidae-and-aleurodidae-of-guam/bounding_box_images/Aphis-gossypii-0.jpg\n",
      "b172/aphidae-and-aleurodidae-of-guam/bounding_box_images/Aphis-maidis-1.jpg\n",
      "b172/aphidae-and-aleurodidae-of-guam/bounding_box_images/Aphis-nerii-2.jpg\n",
      "b172/aphidae-and-aleurodidae-of-guam/bounding_box_images/Neomaskellia-bergii-3.jpg\n",
      "b172/aphidae-and-aleurodidae-of-guam/bounding_box_images/Neomaskellia-bergii-4.jpg\n",
      "Merging bounding box images.\n",
      "species_names:           species_name\n",
      "0       Aphis gossypii\n",
      "1         Aphis maidis\n",
      "2          Aphis nerii\n",
      "3  Neomaskellia bergii\n",
      "Aphis gossypii\n",
      "               bb_image\n",
      "0  Aphis-gossypii-0.jpg\n",
      "\n",
      "rowcount: 1\n",
      "f: b172/aphidae-and-aleurodidae-of-guam/bounding_box_images/Aphis-gossypii-0.jpg\n",
      "Aphis maidis\n",
      "             bb_image\n",
      "0  Aphis-maidis-1.jpg\n",
      "\n",
      "rowcount: 1\n",
      "f: b172/aphidae-and-aleurodidae-of-guam/bounding_box_images/Aphis-maidis-1.jpg\n",
      "Aphis nerii\n",
      "            bb_image\n",
      "0  Aphis-nerii-2.jpg\n",
      "\n",
      "rowcount: 1\n",
      "f: b172/aphidae-and-aleurodidae-of-guam/bounding_box_images/Aphis-nerii-2.jpg\n",
      "Neomaskellia bergii\n",
      "                    bb_image\n",
      "0  Neomaskellia-bergii-3.jpg\n",
      "1  Neomaskellia-bergii-4.jpg\n",
      "\n",
      "rowcount: 2\n",
      "f: b172/aphidae-and-aleurodidae-of-guam/bounding_box_images/Neomaskellia-bergii-3.jpg\n",
      "[[255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " ...\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]]\n",
      "f: b172/aphidae-and-aleurodidae-of-guam/bounding_box_images/Neomaskellia-bergii-4.jpg\n",
      "Making mturk data csv.\n",
      "performing optical character recognition on b172/aphidae-and-aleurodidae-of-guam/merged_images/Aphis maidis.jpg\n",
      "performing optical character recognition on b172/aphidae-and-aleurodidae-of-guam/merged_images/Neomaskellia bergii.jpg\n",
      "performing optical character recognition on b172/aphidae-and-aleurodidae-of-guam/merged_images/Aphis nerii.jpg\n",
      "performing optical character recognition on b172/aphidae-and-aleurodidae-of-guam/merged_images/Aphis gossypii.jpg\n",
      "\n",
      "neuropteroid-insects-from-guam\n",
      "bb_xml_path_exists: False\n",
      "bb_csv_path_exists: False\n",
      "\n",
      "butterflies-of-guam\n",
      "bb_xml_path_exists: False\n",
      "bb_csv_path_exists: False\n",
      "\n",
      "sphingidae-of-guam\n",
      "bb_xml_path_exists: False\n",
      "bb_csv_path_exists: False\n",
      "\n",
      "staphylinidae-of-guam\n",
      "bb_xml_path_exists: False\n",
      "bb_csv_path_exists: False\n",
      "\n",
      "rhipiceridae-of-guam\n",
      "bb_xml_path_exists: False\n",
      "bb_csv_path_exists: False\n",
      "\n",
      "ciidae-of-guam\n",
      "bb_xml_path_exists: False\n",
      "bb_csv_path_exists: False\n",
      "\n",
      "elaterid-and-eucnemid-beetles-of-guam\n",
      "bb_xml_path_exists: False\n",
      "bb_csv_path_exists: False\n",
      "\n",
      "coleoptera-heteromera-from-guam\n",
      "bb_xml_path_exists: False\n",
      "bb_csv_path_exists: False\n",
      "\n",
      "new-longicorn-beetles-from-guam-cerambycidae\n",
      "bb_xml_path_exists: False\n",
      "bb_csv_path_exists: False\n",
      "\n",
      "anthribidae-of-guam\n",
      "bb_xml_path_exists: True\n",
      "bb_csv_path_exists: True\n",
      "\n",
      "curculionidae-of-guam\n",
      "bb_xml_path_exists: False\n",
      "bb_csv_path_exists: False\n",
      "\n",
      "barkbeetles-of-guam\n",
      "bb_xml_path_exists: True\n",
      "bb_csv_path_exists: True\n",
      "\n",
      "miscellaneous-families-of-guam-coleoptera\n",
      "bb_xml_path_exists: False\n",
      "bb_csv_path_exists: False\n",
      "\n",
      "stylopidae-of-guam\n",
      "bb_xml_path_exists: False\n",
      "bb_csv_path_exists: False\n",
      "\n",
      "formicidae-of-guam\n",
      "bb_xml_path_exists: False\n",
      "bb_csv_path_exists: False\n",
      "\n",
      "wasps-of-guam\n",
      "bb_xml_path_exists: False\n",
      "bb_csv_path_exists: False\n",
      "\n",
      "bees-of-guam\n",
      "bb_xml_path_exists: False\n",
      "bb_csv_path_exists: False\n",
      "\n",
      "halictine-bees-from-rota-island\n",
      "bb_xml_path_exists: False\n",
      "bb_csv_path_exists: False\n",
      "\n",
      "tipulidae-of-guam\n",
      "bb_xml_path_exists: False\n",
      "bb_csv_path_exists: False\n",
      "\n",
      "culicidae-of-guam\n",
      "bb_xml_path_exists: False\n",
      "bb_csv_path_exists: False\n",
      "\n",
      "trypetidae-otitidae-helomyzidae-and-clusiidae-of-guam-diptera\n",
      "bb_xml_path_exists: False\n",
      "bb_csv_path_exists: False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "f = '{}/{}.csv'.format(bulletin, bulletin)\n",
    "df = pd.read_csv(f)\n",
    "for section in df.slug.values:\n",
    "    print(section)\n",
    "    bb_xml_path = '{}/{}/{}.xml'.format(bulletin, section, section)\n",
    "    bb_xml_path_exists = os.path.exists(bb_xml_path)\n",
    "    print('bb_xml_path_exists: {}'.format(bb_xml_path_exists))\n",
    "    bb_csv_path = '{}/{}/bounding_boxes.csv'.format(bulletin, section)\n",
    "    bb_csv_path_exists = os.path.exists(bb_csv_path)\n",
    "    print('bb_csv_path_exists: {}'.format(bb_csv_path_exists))\n",
    "    \n",
    "    if bb_xml_path_exists and not bb_csv_path_exists:\n",
    "        print('Making bb table for {}'.format(section))\n",
    "        make_bounding_box_table(bulletin, section)\n",
    "        \n",
    "        print('Extracting bounding box images.')\n",
    "        extract_bounding_box_images(bulletin, section)\n",
    "        \n",
    "        print('Merging bounding box images.')\n",
    "        merge_bounding_box_images(bulletin, section)\n",
    "        \n",
    "        print('Making mturk data csv.')\n",
    "        make_mturk_data_csv(bulletin, section)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep\n",
    "\n",
    "## Step 1: Get PDF copies of Insects of Guam I and II (Bulletin 172 and 189)\n",
    "```\n",
    "mkdir B172\n",
    "cd B172\n",
    "wget --convert-links http://hbs.bishopmuseum.org/pubs-online/bpbm-bulletins.html\n",
    "grep -o 'hbs.bishopmuseum.org/pubs-online/pdf/b172p[1-9].*\\.pdf' bpbm-bulletins.html > B172-pdfs.txt\n",
    "wget -i B172-pdfs.txt\n",
    "cd ..\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "print(os.getcwd())\n",
    "if not os.path.exists('caca'):\n",
    "    os.mkdir('caca')\n",
    "os.chdir('caca')\n",
    "print(os.getcwd())\n",
    "os.chdir('..')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grep does not work\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "subprocess.call(['mkdir', 'B999'])\n",
    "os.chdir('B999')\n",
    "subprocess.call(['wget', '--convert-links', 'http://hbs.bishopmuseum.org/pubs-online/bpbm-bulletins.html'])\n",
    "\n",
    "outfile = open('titles-urls.htm', 'w')\n",
    "subprocess.call(['grep', 'hbs.bishopmuseum.org/pubs-online/pdf/b172p[1-9].*\\.pdf', 'bpbm-bulletins.html'],\n",
    "                shell=True, \n",
    "                stdout=outfile)\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Extract species sections from each PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "os.chdir('B172')\n",
    "filepath = 'titles-urls.htm'\n",
    "with open(filepath) as fp:\n",
    "    for cnt, line in enumerate(fp):\n",
    "       #print(\"Line {}: {}\".format(cnt, line))\n",
    "       line = line.replace('&nbsp;', '').replace('[', '').replace(']', '')\n",
    "       line = line.replace(', by ', '|').replace('<img', '|').replace('href=\"', '|').replace('pdf\"', 'pdf|')\n",
    "       parts = line.split('|')\n",
    "       if (len(parts) == 5):\n",
    "            title = parts[0].strip()\n",
    "            authors = parts[1].strip()\n",
    "            url = parts[3].strip()\n",
    "            print('{}\\n{}\\n{}\\n\\n'.format(title, authors, url))\n",
    "            \n",
    "            directory = title.replace(' ','-')\n",
    "            subprocess.call(['mkdir', directory])\n",
    "            os.chdir(directory)\n",
    "            subprocess.call(['wget', url])\n",
    "            pdf = url.split('/')[-1]\n",
    "            #subprocess.call(['pdftk', pdf, 'burst'])\n",
    "            jpg = pdf.replace('pdf', 'jpg')\n",
    "            print(jpg)\n",
    "            subprocess.call(['convert', '-density', '200x200', pdf, jpg])\n",
    "            os.chdir('..')\n",
    "os.chdir('..')\n",
    "print('FINIS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET  \n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import json\n",
    "try:\n",
    "    from PIL import Image\n",
    "except ImportError:\n",
    "    import Image\n",
    "import pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_mturk_results(results_csv_filename):\n",
    "    \"\"\"\n",
    "    Returns a dataframe.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(results_csv_filename)\n",
    "    df = df[['Input.image_url', 'Answer.annotatedResult.boundingBoxes']]\n",
    "    df.columns =['image_url','bounding_boxes']\n",
    "\n",
    "    box_list = []\n",
    "    for i, r in df.iterrows():\n",
    "        image_fn = r['image_url'].split('/')[-1]\n",
    "        boxes = json.loads(r['bounding_boxes'])\n",
    "        for box in boxes:\n",
    "            box_dict = {\n",
    "                'image_fn': image_fn,\n",
    "                'box_type': box['label'],\n",
    "                'left': box['left'],\n",
    "                'top': box['top'],\n",
    "                'width': box['width'],\n",
    "                'height': box['height']\n",
    "            }\n",
    "            box_list.append(box_dict) \n",
    "    df_boxes = pd.DataFrame(box_list)\n",
    "    df_boxes.sort_values(['image_fn', 'top'], inplace=True)\n",
    "    \n",
    "    # Check that there is a max of one 'Species section orphan' per image_fn\n",
    "    # and that this section is nearest the top\n",
    "    \n",
    "    \n",
    "    return df_boxes\n",
    "\n",
    "#df = parse_mturk_results('Batch_235921_batch_results.csv')\n",
    "#df"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def check_orphans(df):\n",
    "    \"\"\"\n",
    "    Checks that each page contains 0 or 1 species section orphans.\n",
    "    Checks that, if an orphan exists, it precedes all species sections.\n",
    "    \"\"\"\n",
    "    for image_fn in df.image_fn.unique():\n",
    "        df_temp = df[df['image_fn']==image_fn].reset_index()\n",
    "        print image_fn, 'Number of sections:', len(df_temp)\n",
    "        orphan_count = len(df_temp[df_temp.box_type == 'Species section orphan'])\n",
    "        print image_fn, 'orphan_count:', orphan_count\n",
    "        if orphan_count > 1:\n",
    "            print image_fn, 'ERROR: More than 1 species section orphans on this page'\n",
    "            return\n",
    "        if orphan_count == 1:\n",
    "            orphan_index = df_temp[df_temp.box_type == 'Species section orphan'].index.item()\n",
    "            print image_fn, 'orphan_index:', orphan_index\n",
    "            if orphan_index > 0:\n",
    "                print image_fn, 'ERROR: Orphan is preceded by a species section on this page.'\n",
    "                return\n",
    "        print\n",
    "    return 'OK'\n",
    "\n",
    "#check_orphans(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attach_orphans():\n",
    "    \"\"\"\n",
    "    If the entry for a species section spans more that one page, there will be two images extracted,\n",
    "    saved with file names with include 'species section' and 'species section orphan'. \n",
    "    This function combines glues the 'species section orphan' images to the bottom of the preceeding\n",
    "    'species section' images.\n",
    "    \"\"\"\n",
    "    file_list = glob.glob('boxes/*.jpg')\n",
    "    file_list.sort()\n",
    "    number_of_images_combined = 0\n",
    "    for i, fn in enumerate(file_list):\n",
    "        if i>0:\n",
    "            fn_prev = file_list[i-1]\n",
    "            if 'orphan' in fn:\n",
    "                #print 'Combining {} and {}'.format(fn_prev, fn)\n",
    "                img1 = cv2.imread(fn_prev, 0)\n",
    "                img2 = cv2.imread(fn, 0)\n",
    "                new_img = combine_images_vertically(img1, img2) \n",
    "\n",
    "                # Overwrite the original 'species section' image file with the combined file.\n",
    "                cv2.imwrite(fn_prev, new_img)\n",
    "\n",
    "                # Delete the 'species section orphan' file.\n",
    "                os.remove(fn) \n",
    "                number_of_images_combined += 1\n",
    "    return number_of_images_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_images_mturk(df):\n",
    "    \"\"\"\n",
    "    REWRITE THIS\n",
    "    Box is a dict containing coordinates for a bounding box. Example:\n",
    "    \n",
    "        {'image_name': 'odonata-3.jpg',\n",
    "         'species_name': 'Tramea limbata',\n",
    "         'xbr': 1223,\n",
    "         'xtl': 250,\n",
    "         'ybr': 716,\n",
    "         'ytl': 348}\n",
    "         \n",
    "    This information to generate an image which is written to a file. Example:\n",
    "    \n",
    "        'boxes/Tramea limbata-odonata-3.jpg'    \n",
    "    \"\"\"\n",
    "    for i,r in df.iterrows():\n",
    "        #print r.image_fn\n",
    "        im = cv2.imread('odonata/'+r.image_fn)\n",
    "        #print r.top\n",
    "        #print r.height\n",
    "        #print r.left\n",
    "        #print r.width\n",
    "        roi = im[r.top: r.top+r.height-1, r.left:r.left+r.width-1]\n",
    "        roi_filename = 'boxes/{:03d}-{}-{}'.format(i, r.box_type, r.image_fn)\n",
    "        cv2.imwrite(roi_filename, roi)\n",
    "        #print roi_filename\n",
    "    return\n",
    "\n",
    "#extract_images_mturk(df)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "def parse_cvat_xml(xml_file):\n",
    "    \"\"\"\n",
    "    Parses an XML file generated by CVAT.\n",
    "    Returns a list of dicts containing bounding box coordinates. \n",
    "    \"\"\"\n",
    "    box_list = []\n",
    "    tree = ET.parse(xml_file) \n",
    "    for image in tree.findall('image'):\n",
    "        for box in image.findall('box'):\n",
    "            box_list.append({\n",
    "                'image_name': image.get('name'),\n",
    "                'species_name':box.find('attribute').text,\n",
    "                'xtl': int(float(box.attrib.get('xtl'))),\n",
    "                'ytl': int(float(box.attrib.get('ytl'))),\n",
    "                'xbr': int(float(box.attrib.get('xbr'))),\n",
    "                'ybr': int(float(box.attrib.get('ybr')))           \n",
    "            })\n",
    "    return box_list        "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def extract_image(box):\n",
    "    \"\"\"\n",
    "    Box is a dict containing coordinates for a bounding box. Example:\n",
    "    \n",
    "        {'image_name': 'odonata-3.jpg',\n",
    "         'species_name': 'Tramea limbata',\n",
    "         'xbr': 1223,\n",
    "         'xtl': 250,\n",
    "         'ybr': 716,\n",
    "         'ytl': 348}\n",
    "         \n",
    "    This information to generate an image which is written to a file. Example:\n",
    "    \n",
    "        'boxes/Tramea limbata-odonata-3.jpg'    \n",
    "    \"\"\"\n",
    "    im = cv2.imread(box['image_name'])\n",
    "    roi = im[box['ytl']:box['ybr'], box['xtl']:box['xbr']]\n",
    "    roi_filename = 'boxes/{}-{}'.format(box['species_name'], box['image_name'])\n",
    "    cv2.imwrite(roi_filename, roi)\n",
    "    return roi_filename"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def glue_images():\n",
    "    \"\"\"\n",
    "    If the entry for a species spans more that one page, there will be two or more images extracted. This function\n",
    "    finds instances of multiple images for a species and pastes them together. \n",
    "    \n",
    "    This function should be repeated until the number_of_images_combined returned is zero:\n",
    "    \n",
    "        while True:\n",
    "            if glue_boxes() == 0:\n",
    "                break\n",
    "    \"\"\"\n",
    "\n",
    "    file_list = glob.glob('boxes/*.jpg')\n",
    "    file_list.sort()\n",
    "\n",
    "    number_of_images_combined = 0\n",
    "    for i, fn in enumerate(file_list):\n",
    "        if i>0:\n",
    "            fn_prev = file_list[i-1]\n",
    "            if fn.split('-')[0] == fn_prev.split('-')[0]:\n",
    "                print 'Combining {} and {}'.format(fn_prev, fn)\n",
    "                number_of_images_combined += 1\n",
    "\n",
    "                img1 = cv2.imread(fn_prev, 0)\n",
    "                img2 = cv2.imread(fn, 0)\n",
    "                h1, w1 = img1.shape\n",
    "                h2, w2 = img2.shape\n",
    "\n",
    "                # Create an array big enough to hold img2 below img1.\n",
    "                new = np.zeros(((h1 + h2), max(w1, w2)), np.float32)\n",
    "\n",
    "                # Paste img1 at y=0, x=0\n",
    "                new[0:img1.shape[0], 0:img1.shape[1]] = img1\n",
    "\n",
    "                # Paste img2 at y=h1, x=0\n",
    "                new[h1:h1+img2.shape[0],0:img2.shape[1]] = img2\n",
    "\n",
    "                # Overwrite fn_prev\n",
    "                cv2.imwrite(fn_prev, new)\n",
    "\n",
    "                # Delete fn\n",
    "                os.remove(fn) \n",
    "    return number_of_images_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download PDF\n",
    "```\n",
    "wget http://hbs.bishopmuseum.org/pubs-online/pdf/b172p3-6.pdf -O odonata.pdf\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert PDF into a set of JPGs\n",
    "\n",
    "```\n",
    "convert -density 200x200 odonata.pdf odonata.jpg\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Place bounding boxes around ROIs using MTurk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```html\n",
    "<!-- You must include this JavaScript file -->\n",
    "<script src=\"https://assets.crowd.aws/crowd-html-elements.js\"></script>\n",
    "\n",
    "<!-- For the full list of available Crowd HTML Elements and their input/output documentation,\n",
    "      please refer to https://docs.aws.amazon.com/sagemaker/latest/dg/sms-ui-template-reference.html -->\n",
    "\n",
    "<!-- You must include crowd-form so that your task submits answers to MTurk -->\n",
    "<crowd-form answer-format=\"flatten-objects\">\n",
    "\n",
    "    <!-- The crowd-bounding-box element will create a tool for the Worker to draw \n",
    "           labeled boxes around the specified objects in your image.\n",
    "\n",
    "          Your image file URLs will be substituted for the \"image_url\" variable below \n",
    "          when you publish a batch with a CSV input file containing multiple image file URLs.\n",
    "          To preview the element with an example image, try setting the src attribute to\n",
    "          \"https://s3.amazonaws.com/cv-demo-images/two-birds.jpg\" -->\n",
    "    <crowd-bounding-box \n",
    "        src=\"${image_url}\"\n",
    "        labels=\"['Species section', 'Species section orphan']\"\n",
    "        header=\"Draw bounding boxes around the requested items\"\n",
    "        name=\"annotatedResult\">\n",
    "\n",
    "        <!-- Use the short-instructions section for quick instructions that the Worker\n",
    "              will see while working on the task. Including some basic examples of \n",
    "              good and bad answers here can help get good results. You can include \n",
    "              any HTML here. -->\n",
    "        <short-instructions>Draw boxes around the requested target of interest.</short-instructions>\n",
    "\n",
    "        <!-- Use the full-instructions section for more detailed instructions that the \n",
    "              Worker can open while working on the task. Including more detailed \n",
    "              instructions and additional examples of good and bad answers here can\n",
    "              help get good results. You can include any HTML here. -->\n",
    "        <full-instructions header=\"Bounding Box Instructions\">\n",
    "            <p>Use the bounding box tool to draw boxes around the requested target of interest:</p>\n",
    "            <ol>\n",
    "              \t<li>Draw a rectangle using your mouse over each instance of the target.</li>\n",
    "                <li>Make sure the box does not cut into the target, leave a 2 - 3 pixel margin</li>\n",
    "               \t<li>When targets are overlapping, draw a box around each object, include all \n",
    "                      contiguous parts of the target in the box. Do not include parts that are completely \n",
    "                      overlapped by another object.</li>\n",
    "               \t<li>Do not include parts of the target that cannot be seen, even though you think you \n",
    "                      can interpolate the whole shape of the target.</li>\n",
    "               \t<li>Avoid shadows, they're not considered as a part of the target.</li>\n",
    "               \t<li>If the target goes off the screen, label up to the edge of the image.</li>\n",
    "            </ol>\n",
    "        </full-instructions>\n",
    "\n",
    "    </crowd-bounding-box>\n",
    "</crowd-form>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract bounding boxes as a set of JPGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'parse_mturk_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-48efddcece8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmturk_results_csv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Batch_235921_batch_results.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_mturk_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmturk_results_csv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mextract_images_mturk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mattach_orphans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'parse_mturk_results' is not defined"
     ]
    }
   ],
   "source": [
    "mturk_results_csv = 'Batch_235921_batch_results.csv'\n",
    "\n",
    "df = parse_mturk_results(mturk_results_csv)\n",
    "extract_images_mturk(df)\n",
    "attach_orphans();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update GitHub repository\n",
    "```bash\n",
    "git add .\n",
    "git commit -m 'add species section images'\n",
    "git push\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract data from species section images using MTurk\n",
    "\n",
    "```html\n",
    "<head>\n",
    "  <title>My Design with Bootstrap</title>\n",
    "  <meta charset=\"utf-8\">\n",
    "  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n",
    "  <link rel=\"stylesheet\" href=\"https://maxcdn.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css\">\n",
    "  <script src=\"https://ajax.googleapis.com/ajax/libs/jquery/3.4.0/jquery.min.js\"></script>\n",
    "  <script src=\"https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js\"></script>\n",
    "  <script src=\"https://maxcdn.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js\"></script>\n",
    "  <!-- You must include this JavaScript file -->\n",
    "  <script src=\"https://assets.crowd.aws/crowd-html-elements.js\"></script>\n",
    "</head>\n",
    "<body>\n",
    "   <div class=\"container\">\n",
    "        <div class=\"row\">\n",
    "            <div class=\"col-sm-6\">\n",
    "                <p><img src=\"${image_url}\" style=\"max-width: 100%\" /></p>\n",
    "                <p class=\"small\">${text}</p>\n",
    "            </div>\n",
    "            <div class=\"col-sm-6\">\n",
    "                <crowd-form answer-format=\"flatten-objects\">\n",
    "                    <p><strong>Instructions: </strong></p>\n",
    "                    <div><crowd-input label=\"Scientific name\" name=\"scientific_name\" required></div>\n",
    "                    <div><crowd-text-area label=\"Collection records\" name=\"collection_records\"></div>\n",
    "                    <div><crowd-checkbox name=\"first_record\"> First record for Guam</div>\n",
    "                </crowd-form>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "</body>\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/aubreymoore/insects-of-guam/raw/master/boxes/000-Species%20section-odonata-0.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate csv file containing image_urls and text (html)\n",
    "# This file will be used by MTurk\n",
    "\n",
    "prefix = 'https://github.com/aubreymoore/insects-of-guam-datamining/raw/master/'\n",
    "filelist = glob.glob('boxes/*.jpg')\n",
    "filelist.sort()    \n",
    "with open('mturk_data.csv', 'w+') as f:\n",
    "    f.write('image_url,text\\n')\n",
    "    for fn in filelist:\n",
    "        image_url = prefix + fn\n",
    "        print(image_url)\n",
    "        \n",
    "        # Perform optical character recognition on the image\n",
    "        #text = pytesseract.image_to_string(Image.open(fn)).encode('utf-8')\n",
    "        text = pytesseract.image_to_string(Image.open(fn))\n",
    "        \n",
    "        # Remove double quotes and replace line feeds with <br>\n",
    "        text = text.replace('\\n\\n', '\\n')\n",
    "        text = text.replace('\"', '').replace('\\n', '<br>')\n",
    "        \n",
    "        # Separate collection records into individual lines of text\n",
    "        text = text.replace(';', '<br>')\n",
    "        \n",
    "        f.write('{},\"{}\"\\n'.format(image_url, text))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "if not os.path.exists('ocr'):\n",
    "    os.makedirs('ocr')\n",
    "filelist = glob.glob('boxes/*.jpg')\n",
    "filelist.sort()\n",
    "for fn in filelist:\n",
    "    text = pytesseract.image_to_string(Image.open(fn))\n",
    "    text = text.replace('\\n\\n', '\\n')\n",
    "    \n",
    "    # Separate collection records into individual lines of text\n",
    "    text = text.replace('; ', '\\n')\n",
    "\n",
    "    fn = fn.replace('boxes', 'ocr')\n",
    "    fn = fn.replace('.jpg', '.txt')\n",
    "    with open(fn, 'w+') as f:\n",
    "        f.write(text.encode('utf-8')) \n",
    "    print fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist = glob.glob('boxes/*.jpg')\n",
    "filelist\n",
    "\n",
    "fn = filelist[5]\n",
    "text = pytesseract.image_to_string(Image.open(fn))\n",
    "text = text.replace('\\n\\n', '\\n')\n",
    "\n",
    "# Separate collection records into individual lines of text\n",
    "text = text.replace('; ', '\\n')\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Agrionaptera insignis insignis (Rambur)\n",
    "\n",
    "Orote Peninsula | April 9 | Bryan\n",
    "Yigo | April 13 | Bryan\n",
    "Mt. Alifan | April 20 | Bryan\n",
    "Mt. Alifan | April 21 | Bryan\n",
    "Mt. Alifan | April 30 | Bryan\n",
    "Agana | May 4 | Bryan, Swezey, Usinger\n",
    "Agana | May 25 | Bryan, Swezey, Usinger\n",
    "Inarajan | May 7 | Swezey\n",
    "Umatac | May 14 | Usinger\n",
    "Dededo | Aug. 11 | Swezey\n",
    "\n",
    "First Island Record"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
