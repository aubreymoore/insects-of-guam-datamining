{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET  \n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_mturk_results(results_csv_filename):\n",
    "    \"\"\"\n",
    "    Returns a dataframe.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(results_csv_filename)\n",
    "    df = df[['Input.image_url', 'Answer.annotatedResult.boundingBoxes']]\n",
    "    df.columns =['image_url','bounding_boxes']\n",
    "\n",
    "    box_list = []\n",
    "    for i, r in df.iterrows():\n",
    "        image_fn = r['image_url'].split('/')[-1]\n",
    "        boxes = json.loads(r['bounding_boxes'])\n",
    "        for box in boxes:\n",
    "            box_dict = {\n",
    "                'image_fn': image_fn,\n",
    "                'box_type': box['label'],\n",
    "                'left': box['left'],\n",
    "                'top': box['top'],\n",
    "                'width': box['width'],\n",
    "                'height': box['height']\n",
    "            }\n",
    "            box_list.append(box_dict) \n",
    "    df_boxes = pd.DataFrame(box_list)\n",
    "    df_boxes.sort_values(['image_fn', 'top'], inplace=True)\n",
    "    \n",
    "    # Check that there is a max of one 'Species section orphan' per image_fn\n",
    "    # and that this section is nearest the top\n",
    "    \n",
    "    \n",
    "    return df_boxes\n",
    "\n",
    "#df = parse_mturk_results('Batch_235921_batch_results.csv')\n",
    "#df"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def check_orphans(df):\n",
    "    \"\"\"\n",
    "    Checks that each page contains 0 or 1 species section orphans.\n",
    "    Checks that, if an orphan exists, it precedes all species sections.\n",
    "    \"\"\"\n",
    "    for image_fn in df.image_fn.unique():\n",
    "        df_temp = df[df['image_fn']==image_fn].reset_index()\n",
    "        print image_fn, 'Number of sections:', len(df_temp)\n",
    "        orphan_count = len(df_temp[df_temp.box_type == 'Species section orphan'])\n",
    "        print image_fn, 'orphan_count:', orphan_count\n",
    "        if orphan_count > 1:\n",
    "            print image_fn, 'ERROR: More than 1 species section orphans on this page'\n",
    "            return\n",
    "        if orphan_count == 1:\n",
    "            orphan_index = df_temp[df_temp.box_type == 'Species section orphan'].index.item()\n",
    "            print image_fn, 'orphan_index:', orphan_index\n",
    "            if orphan_index > 0:\n",
    "                print image_fn, 'ERROR: Orphan is preceded by a species section on this page.'\n",
    "                return\n",
    "        print\n",
    "    return 'OK'\n",
    "\n",
    "#check_orphans(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attach_orphans():\n",
    "    \"\"\"\n",
    "    If the entry for a species section spans more that one page, there will be two images extracted,\n",
    "    saved with file names with include 'species section' and 'species section orphan'. \n",
    "    This function combines glues the 'species section orphan' images to the bottom of the preceeding\n",
    "    'species section' images.\n",
    "    \"\"\"\n",
    "    file_list = glob.glob('boxes/*.jpg')\n",
    "    file_list.sort()\n",
    "    number_of_images_combined = 0\n",
    "    for i, fn in enumerate(file_list):\n",
    "        if i>0:\n",
    "            fn_prev = file_list[i-1]\n",
    "            if 'orphan' in fn:\n",
    "                #print 'Combining {} and {}'.format(fn_prev, fn)\n",
    "                img1 = cv2.imread(fn_prev, 0)\n",
    "                img2 = cv2.imread(fn, 0)\n",
    "                new_img = combine_images_vertically(img1, img2) \n",
    "\n",
    "                # Overwrite the original 'species section' image file with the combined file.\n",
    "                cv2.imwrite(fn_prev, new_img)\n",
    "\n",
    "                # Delete the 'species section orphan' file.\n",
    "                os.remove(fn) \n",
    "                number_of_images_combined += 1\n",
    "    return number_of_images_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_images_mturk(df):\n",
    "    \"\"\"\n",
    "    REWRITE THIS\n",
    "    Box is a dict containing coordinates for a bounding box. Example:\n",
    "    \n",
    "        {'image_name': 'odonata-3.jpg',\n",
    "         'species_name': 'Tramea limbata',\n",
    "         'xbr': 1223,\n",
    "         'xtl': 250,\n",
    "         'ybr': 716,\n",
    "         'ytl': 348}\n",
    "         \n",
    "    This information to generate an image which is written to a file. Example:\n",
    "    \n",
    "        'boxes/Tramea limbata-odonata-3.jpg'    \n",
    "    \"\"\"\n",
    "    for i,r in df.iterrows():\n",
    "        #print r.image_fn\n",
    "        im = cv2.imread('odonata/'+r.image_fn)\n",
    "        #print r.top\n",
    "        #print r.height\n",
    "        #print r.left\n",
    "        #print r.width\n",
    "        roi = im[r.top: r.top+r.height-1, r.left:r.left+r.width-1]\n",
    "        roi_filename = 'boxes/{:03d}-{}-{}'.format(i, r.box_type, r.image_fn)\n",
    "        cv2.imwrite(roi_filename, roi)\n",
    "        #print roi_filename\n",
    "    return\n",
    "\n",
    "#extract_images_mturk(df)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "def parse_cvat_xml(xml_file):\n",
    "    \"\"\"\n",
    "    Parses an XML file generated by CVAT.\n",
    "    Returns a list of dicts containing bounding box coordinates. \n",
    "    \"\"\"\n",
    "    box_list = []\n",
    "    tree = ET.parse(xml_file) \n",
    "    for image in tree.findall('image'):\n",
    "        for box in image.findall('box'):\n",
    "            box_list.append({\n",
    "                'image_name': image.get('name'),\n",
    "                'species_name':box.find('attribute').text,\n",
    "                'xtl': int(float(box.attrib.get('xtl'))),\n",
    "                'ytl': int(float(box.attrib.get('ytl'))),\n",
    "                'xbr': int(float(box.attrib.get('xbr'))),\n",
    "                'ybr': int(float(box.attrib.get('ybr')))           \n",
    "            })\n",
    "    return box_list        "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def extract_image(box):\n",
    "    \"\"\"\n",
    "    Box is a dict containing coordinates for a bounding box. Example:\n",
    "    \n",
    "        {'image_name': 'odonata-3.jpg',\n",
    "         'species_name': 'Tramea limbata',\n",
    "         'xbr': 1223,\n",
    "         'xtl': 250,\n",
    "         'ybr': 716,\n",
    "         'ytl': 348}\n",
    "         \n",
    "    This information to generate an image which is written to a file. Example:\n",
    "    \n",
    "        'boxes/Tramea limbata-odonata-3.jpg'    \n",
    "    \"\"\"\n",
    "    im = cv2.imread(box['image_name'])\n",
    "    roi = im[box['ytl']:box['ybr'], box['xtl']:box['xbr']]\n",
    "    roi_filename = 'boxes/{}-{}'.format(box['species_name'], box['image_name'])\n",
    "    cv2.imwrite(roi_filename, roi)\n",
    "    return roi_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_images_vertically(img1, img2):\n",
    "    \"\"\"\n",
    "    Glues 2 images together with img2 below img1.\n",
    "    Returns the new compound image.\n",
    "    \"\"\"\n",
    "    h1, w1 = img1.shape\n",
    "    h2, w2 = img2.shape\n",
    "\n",
    "    # Create an array big enough to hold img2 below img1.\n",
    "    img = np.zeros(((h1 + h2), max(w1, w2)), np.float32)\n",
    "\n",
    "    # Paste img1 at y=0, x=0\n",
    "    img[0:img1.shape[0], 0:img1.shape[1]] = img1\n",
    "\n",
    "    # Paste img2 at y=h1, x=0\n",
    "    img[h1:h1+img2.shape[0],0:img2.shape[1]] = img2    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def glue_images():\n",
    "    \"\"\"\n",
    "    If the entry for a species spans more that one page, there will be two or more images extracted. This function\n",
    "    finds instances of multiple images for a species and pastes them together. \n",
    "    \n",
    "    This function should be repeated until the number_of_images_combined returned is zero:\n",
    "    \n",
    "        while True:\n",
    "            if glue_boxes() == 0:\n",
    "                break\n",
    "    \"\"\"\n",
    "\n",
    "    file_list = glob.glob('boxes/*.jpg')\n",
    "    file_list.sort()\n",
    "\n",
    "    number_of_images_combined = 0\n",
    "    for i, fn in enumerate(file_list):\n",
    "        if i>0:\n",
    "            fn_prev = file_list[i-1]\n",
    "            if fn.split('-')[0] == fn_prev.split('-')[0]:\n",
    "                print 'Combining {} and {}'.format(fn_prev, fn)\n",
    "                number_of_images_combined += 1\n",
    "\n",
    "                img1 = cv2.imread(fn_prev, 0)\n",
    "                img2 = cv2.imread(fn, 0)\n",
    "                h1, w1 = img1.shape\n",
    "                h2, w2 = img2.shape\n",
    "\n",
    "                # Create an array big enough to hold img2 below img1.\n",
    "                new = np.zeros(((h1 + h2), max(w1, w2)), np.float32)\n",
    "\n",
    "                # Paste img1 at y=0, x=0\n",
    "                new[0:img1.shape[0], 0:img1.shape[1]] = img1\n",
    "\n",
    "                # Paste img2 at y=h1, x=0\n",
    "                new[h1:h1+img2.shape[0],0:img2.shape[1]] = img2\n",
    "\n",
    "                # Overwrite fn_prev\n",
    "                cv2.imwrite(fn_prev, new)\n",
    "\n",
    "                # Delete fn\n",
    "                os.remove(fn) \n",
    "    return number_of_images_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download PDF\n",
    "```\n",
    "wget http://hbs.bishopmuseum.org/pubs-online/pdf/b172p3-6.pdf -O odonata.pdf\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert PDF into a set of JPGs\n",
    "\n",
    "```\n",
    "convert -density 200x200 odonata.pdf odonata.jpg\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Place bounding boxes around ROIs using MTurk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```html\n",
    "<!-- You must include this JavaScript file -->\n",
    "<script src=\"https://assets.crowd.aws/crowd-html-elements.js\"></script>\n",
    "\n",
    "<!-- For the full list of available Crowd HTML Elements and their input/output documentation,\n",
    "      please refer to https://docs.aws.amazon.com/sagemaker/latest/dg/sms-ui-template-reference.html -->\n",
    "\n",
    "<!-- You must include crowd-form so that your task submits answers to MTurk -->\n",
    "<crowd-form answer-format=\"flatten-objects\">\n",
    "\n",
    "    <!-- The crowd-bounding-box element will create a tool for the Worker to draw \n",
    "           labeled boxes around the specified objects in your image.\n",
    "\n",
    "          Your image file URLs will be substituted for the \"image_url\" variable below \n",
    "          when you publish a batch with a CSV input file containing multiple image file URLs.\n",
    "          To preview the element with an example image, try setting the src attribute to\n",
    "          \"https://s3.amazonaws.com/cv-demo-images/two-birds.jpg\" -->\n",
    "    <crowd-bounding-box \n",
    "        src=\"${image_url}\"\n",
    "        labels=\"['Species section', 'Species section orphan']\"\n",
    "        header=\"Draw bounding boxes around the requested items\"\n",
    "        name=\"annotatedResult\">\n",
    "\n",
    "        <!-- Use the short-instructions section for quick instructions that the Worker\n",
    "              will see while working on the task. Including some basic examples of \n",
    "              good and bad answers here can help get good results. You can include \n",
    "              any HTML here. -->\n",
    "        <short-instructions>Draw boxes around the requested target of interest.</short-instructions>\n",
    "\n",
    "        <!-- Use the full-instructions section for more detailed instructions that the \n",
    "              Worker can open while working on the task. Including more detailed \n",
    "              instructions and additional examples of good and bad answers here can\n",
    "              help get good results. You can include any HTML here. -->\n",
    "        <full-instructions header=\"Bounding Box Instructions\">\n",
    "            <p>Use the bounding box tool to draw boxes around the requested target of interest:</p>\n",
    "            <ol>\n",
    "              \t<li>Draw a rectangle using your mouse over each instance of the target.</li>\n",
    "                <li>Make sure the box does not cut into the target, leave a 2 - 3 pixel margin</li>\n",
    "               \t<li>When targets are overlapping, draw a box around each object, include all \n",
    "                      contiguous parts of the target in the box. Do not include parts that are completely \n",
    "                      overlapped by another object.</li>\n",
    "               \t<li>Do not include parts of the target that cannot be seen, even though you think you \n",
    "                      can interpolate the whole shape of the target.</li>\n",
    "               \t<li>Avoid shadows, they're not considered as a part of the target.</li>\n",
    "               \t<li>If the target goes off the screen, label up to the edge of the image.</li>\n",
    "            </ol>\n",
    "        </full-instructions>\n",
    "\n",
    "    </crowd-bounding-box>\n",
    "</crowd-form>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract bounding boxes as a set of JPGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mturk_results_csv = 'Batch_235921_batch_results.csv'\n",
    "\n",
    "df = parse_mturk_results(mturk_results_csv)\n",
    "extract_images_mturk(df)\n",
    "attach_orphans();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update GitHub repository\n",
    "```bash\n",
    "git add .\n",
    "git commit -m 'add species section images'\n",
    "git push\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract data from species section images using MTurk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/aubreymoore/insects-of-guam/raw/master/boxes/000-Species%20section-odonata-0.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate csv file containing image_urls\n",
    "# This file will be used by MTurk\n",
    "prefix = 'https://github.com/aubreymoore/insects-of-guam/raw/master/'\n",
    "filelist = glob.glob('boxes/*.jpg')\n",
    "filelist.sort()    \n",
    "with open('species-section-image-urls.csv', 'w+') as f:\n",
    "    f.write('image_url' + '\\n')\n",
    "    for fn in filelist:\n",
    "        f.write(prefix + fn + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ocr/000-Species section-odonata-0.txt\n",
      "ocr/001-Species section-odonata-0.txt\n",
      "ocr/003-Species section-odonata-1.txt\n",
      "ocr/004-Species section-odonata-1.txt\n",
      "ocr/005-Species section-odonata-1.txt\n",
      "ocr/006-Species section-odonata-1.txt\n",
      "ocr/008-Species section-odonata-2.txt\n",
      "ocr/009-Species section-odonata-2.txt\n",
      "ocr/010-Species section-odonata-2.txt\n",
      "ocr/011-Species section-odonata-2.txt\n",
      "ocr/013-Species section-odonata-3.txt\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from PIL import Image\n",
    "except ImportError:\n",
    "    import Image\n",
    "import pytesseract\n",
    "\n",
    "\"\"\"\n",
    "def ocr_core(filename):\n",
    "    '''\n",
    "    This function will handle the core OCR processing of images.\n",
    "    '''\n",
    "    text = pytesseract.image_to_string(Image.open(filename))  # We'll use Pillow's Image class to open the image and pytesseract to detect the string in the image\n",
    "    return text  # Then we will print the text in the image\n",
    "\"\"\"\n",
    "    \n",
    "if not os.path.exists('ocr'):\n",
    "    os.makedirs('ocr')\n",
    "filelist = glob.glob('boxes/*.jpg')\n",
    "filelist.sort()\n",
    "for fn in filelist:\n",
    "    text = pytesseract.image_to_string(Image.open(fn))\n",
    "    text = text.replace('\\n\\n', '\\n')\n",
    "    fn = fn.replace('boxes', 'ocr')\n",
    "    fn = fn.replace('.jpg', '.txt')\n",
    "    with open(fn, 'w+') as f:\n",
    "        f.write(text.encode('utf-8')) \n",
    "    print fn"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Agrionaptera insignis insignis (Rambur)\n",
    "\n",
    "Orote Peninsula | April 9 | Bryan\n",
    "Yigo | April 13 | Bryan\n",
    "Mt. Alifan | April 20 | Bryan\n",
    "Mt. Alifan | April 21 | Bryan\n",
    "Mt. Alifan | April 30 | Bryan\n",
    "Agana | May 4 | Bryan, Swezey, Usinger\n",
    "Agana | May 25 | Bryan, Swezey, Usinger\n",
    "Inarajan | May 7 | Swezey\n",
    "Umatac | May 14 | Usinger\n",
    "Dededo | Aug. 11 | Swezey\n",
    "\n",
    "First Island Record"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
