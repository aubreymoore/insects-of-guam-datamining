{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Run with Python 3 kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions (called by other functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_images_vertically(img1, img2):\n",
    "    \"\"\"\n",
    "    Glues 2 images together with img2 below img1.\n",
    "    Returns the new compound image.\n",
    "    \"\"\"\n",
    "    \n",
    "    import numpy as np\n",
    "    \n",
    "    h1, w1 = img1.shape\n",
    "    h2, w2 = img2.shape\n",
    "\n",
    "    # Create an array big enough to hold img2 below img1.\n",
    "    img = np.zeros(((h1 + h2), max(w1, w2)), np.float32)\n",
    "\n",
    "    # Paste img1 at y=0, x=0\n",
    "    img[0:img1.shape[0], 0:img1.shape[1]] = img1\n",
    "\n",
    "    # Paste img2 at y=h1, x=0\n",
    "    img[h1:h1+img2.shape[0],0:img2.shape[1]] = img2    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_bishop_bulletins_page(bulletin):\n",
    "    \"\"\"\n",
    "    Scrapes data from the Bishop Museum pubs online web page. \n",
    "    Bulletin is b172 for Insects of Guam I and b189 for Insects of Guam II.\n",
    "    A directory named b172 or b189 is created and populated with a CSV file, named b189.csv, containing\n",
    "    titles, stubs, authors, and urls for pdfs.\n",
    "    If the bulletin directory already exists, this function does nothing.\n",
    "    \"\"\"\n",
    "    import requests\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    from bs4 import BeautifulSoup\n",
    "    from urllib.parse import urljoin\n",
    "    from slugify import slugify\n",
    "    \n",
    "    if bulletin not in ['b172', 'b189']:\n",
    "        print(\"bulletin not in ['b172', 'b189']\")\n",
    "        return\n",
    "\n",
    "    bulletins_url = 'http://hbs.bishopmuseum.org/pubs-online/bpbm-bulletins.html'\n",
    "    result = requests.get(bulletins_url)\n",
    "    soup = BeautifulSoup(result.content, features = \"lxml\")\n",
    "\n",
    "    pdf_list = []\n",
    "    links = soup.find_all('a')\n",
    "    for link in links:\n",
    "        if bulletin in link.get('href'):\n",
    "            text = link.previous_sibling.previous_sibling.previous_sibling\n",
    "            parts = text.split(', by ')\n",
    "            if len(parts) == 2:\n",
    "                title = parts[0].strip()\n",
    "                slug = slugify(title)\n",
    "                authors = parts[1].replace('[','').strip()          \n",
    "                url = link.get('href')\n",
    "                url = urljoin(bulletins_url, url)\n",
    "                pdf_list.append({'title':title, 'slug':slug, 'authors':authors, 'url':url})\n",
    "    \n",
    "    df_pdf_list = pd.DataFrame(pdf_list)\n",
    "    os.mkdir(bulletin)\n",
    "    outfile = '{}/{}.csv'.format(bulletin, bulletin)\n",
    "    df_pdf_list.to_csv(outfile, index=False)\n",
    "    \n",
    "    return\n",
    "\n",
    "## Usage example:\n",
    "#scrape_bishop_bulletins_page('b172')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import docker\n",
    "\n",
    "client = docker.from_env()\n",
    "\n",
    "for container in client.containers.list():\n",
    "    container.stop()\n",
    "\n",
    "data = container = client.containers.run('cvat', detach=True)\n",
    "print(data)\n",
    "file_json = data.get_archive('testdump.xml')\n",
    "stream, stat = file_json\n",
    "file_obj = BytesIO()\n",
    "for i in stream:\n",
    "    file_obj.write(i)\n",
    "file_obj.seek(0)\n",
    "tar = tarfile.open(mode='r', fileobj=file_obj)\n",
    "text = tar.extractfile('out.json')\n",
    "q = text.read()\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_file_structure(bulletin):\n",
    "    \"\"\"\n",
    "    bulletin is 'b172' for Insects of Guam I and 'b189' for Insects of Guam II.\n",
    "    Depends on scrape_bishop_bulletins_page\n",
    "    Creates a data file structure in this format:\n",
    "    \n",
    "    b172\n",
    "        anthribidae-of-guam\n",
    "            anthribidae-of-guam.pdf\n",
    "            anthribidae-of-guam-0.jpg\n",
    "            anthribidae-of-guam-1.jpg\n",
    "            ...\n",
    "        formicidae-of-guam\n",
    "            formicidae-of-guam.pdf\n",
    "            formicidae-of-guam-0.jpg\n",
    "            formicidae-of-guam-1.jpg\n",
    "            ...\n",
    "            \n",
    "    Each directory contains a PDF file and a JPG image for each page in the PDF.\n",
    "    \n",
    "    \"\"\"\n",
    "    import requests\n",
    "    import os\n",
    "    import subprocess\n",
    "    import pandas as pd\n",
    "    \n",
    "    if bulletin not in ['b172', 'b189']:\n",
    "        print(\"bulletin not in ['b172', 'b189']\")\n",
    "        return\n",
    "    \n",
    "    if not os.path.exists(bulletin):\n",
    "        print('{} directory does not exist.'.format(bulletin))\n",
    "        print('Scraping Bishop Museum Bulletins web page.')\n",
    "        scrape_bishop_bulletins_page(bulletin)\n",
    "    \n",
    "    pdf_list = pd.read_csv('{}/{}.csv'.format(bulletin, bulletin)).to_dict('records')\n",
    "    \n",
    "    os.chdir('b172'); print(os.getcwd())\n",
    "    for d in pdf_list:\n",
    "        slug = d['slug']\n",
    "        if os.path.exists(slug):\n",
    "            print('{} directory already exists.'.format(slug))\n",
    "            continue\n",
    "\n",
    "        # Create a new directory and move into it\n",
    "        url = d['url']\n",
    "        os.mkdir(slug); os.chdir(slug); print(os.getcwd())\n",
    "\n",
    "        # Download PDF\n",
    "        filename = '{}.pdf'.format(slug)\n",
    "        r = requests.get(url)\n",
    "        open(filename, 'wb').write(r.content)\n",
    "\n",
    "        # Create a JPG image for each page in PDF using the Linux convert command\n",
    "        jpg = filename.replace('pdf', 'jpg')\n",
    "        subprocess.call(['convert', '-density', '200x200', filename, jpg])\n",
    "\n",
    "        # Move up one directory\n",
    "        os.chdir('..'); print(os.getcwd())\n",
    "    os.chdir('..'); print(os.getcwd())\n",
    "    return\n",
    "\n",
    "#create_file_structure('b172')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bounding_box_table(bulletin, section):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    from bs4 import BeautifulSoup\n",
    "    import pandas as pd\n",
    "\n",
    "    xml_file_path = '{}/{}/{}.xml'.format(bulletin, section, section)\n",
    "    f = open(xml_file_path, 'r')\n",
    "    contents = f.read()\n",
    "    soup = BeautifulSoup(contents, features = \"lxml\")\n",
    "\n",
    "    bb_list = []\n",
    "    n = -1\n",
    "    for image in soup.find_all('image'):\n",
    "        for box in image.find_all('box'):\n",
    "            n += 1\n",
    "            species_name = box.text.replace('\\n','')\n",
    "            bb_list.append({\n",
    "                'species_name':species_name, \n",
    "                'page_image':image['name'],\n",
    "                'bb_image': '{}-{}.jpg'.format(species_name.replace(' ', '-'), n),\n",
    "                'xtl':int(float(box['xtl'])),\n",
    "                'ytl':int(float(box['ytl'])),\n",
    "                'xbr':int(float(box['xbr'])),\n",
    "                'ybr':int(float(box['ybr']))\n",
    "            })\n",
    "    df_bb_list = pd.DataFrame(bb_list)\n",
    "    outfile = '{}/{}/bounding_boxes.csv'.format(bulletin, section)\n",
    "    df_bb_list.to_csv(outfile, index=False)\n",
    "    return\n",
    "\n",
    "#make_bounding_box_table('b172', 'barkbeetles-of-guam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_bounding_box_images(bulletin, section):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    import cv2\n",
    "    import os\n",
    "    \n",
    "    bb_list_csv_path = '{}/{}/bounding_boxes.csv'.format(bulletin, section)  \n",
    "    df_bb_list = pd.read_csv(bb_list_csv_path)\n",
    "\n",
    "    mydir = '{}/{}/bounding_box_images'.format(bulletin, section)\n",
    "    if not os.path.exists(mydir):\n",
    "        os.mkdir(mydir)\n",
    "\n",
    "    # Extract bounding box images\n",
    "    for i, r in df_bb_list.iterrows():\n",
    "        page_image_path = '{}/{}/{}'.format(bulletin, section, r.page_image)\n",
    "        im = cv2.imread(page_image_path)\n",
    "        roi = im[r.ytl:r.ybr, r.xtl:r.xbr]\n",
    "        roi_filename = '{}/{}'.format(mydir, r.bb_image)\n",
    "        print(roi_filename)    \n",
    "        cv2.imwrite(roi_filename, roi)\n",
    "    return\n",
    "\n",
    "#extract_bounding_box_images('b172', 'barkbeetles-of-guam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_bounding_box_images(bulletin, section):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import pandasql as ps\n",
    "    import cv2\n",
    "    import numpy as np\n",
    "\n",
    "    \n",
    "    bb_list_csv_path = '{}/{}/bounding_boxes.csv'.format(bulletin, section)  \n",
    "    df_bb_list = pd.read_csv(bb_list_csv_path)\n",
    "\n",
    "    mydir = '{}/{}/bounding_box_images'.format(bulletin, section)\n",
    "\n",
    "    merged_image_dir = '{}/{}/merged_images'.format(bulletin, section)\n",
    "    if not os.path.exists(merged_image_dir):\n",
    "        os.mkdir(merged_image_dir)\n",
    "\n",
    "    sql = '''select species_name \n",
    "    from df_bb_list \n",
    "    group by species_name \n",
    "    order by species_name'''\n",
    "    species_names = ps.sqldf(sql)\n",
    "    \n",
    "    print('species_names: {}'.format(species_names))\n",
    "    \n",
    "    for species_name in species_names.values:\n",
    "        species_name = species_name[0]\n",
    "        print(species_name)\n",
    "        sql = '''select bb_image \n",
    "        from df_bb_list \n",
    "        where species_name=\"{}\" \n",
    "        order by bb_image'''.format(species_name)\n",
    "        df = ps.sqldf(sql)\n",
    "        print(df)\n",
    "        print()\n",
    "\n",
    "        rowcount = df.shape[0]\n",
    "        print('rowcount: {}'.format(rowcount))\n",
    "        if rowcount > 2:\n",
    "            print('More than 2 images to be merged. Not implemented. Continuiing.')\n",
    "            continue\n",
    "        if rowcount == 1:\n",
    "            f = '{}/{}'.format(mydir, df.bb_image[0])\n",
    "            print('f: {}'.format(f))\n",
    "            img = cv2.imread(f, 0)\n",
    "            #cv2.imshow('caca',img)\n",
    "        if rowcount == 2:\n",
    "            f = '{}/{}'.format(mydir, df.bb_image[0])\n",
    "            print('f: {}'.format(f))\n",
    "            img1 = cv2.imread(f, 0)\n",
    "            print(img1)\n",
    "            \n",
    "            f = '{}/{}'.format(mydir, df.bb_image[1])\n",
    "            print('f: {}'.format(f))\n",
    "            img2 = cv2.imread(f, 0)  \n",
    "            #print('img1 shape: {}'.format(img1.shp))\n",
    "            #print('img2 shape: {}'.format(img2.shp))\n",
    "            img = combine_images_vertically(img1, img2)\n",
    "        f = '{}/{}.jpg'.format(merged_image_dir, species_name)\n",
    "        cv2.imwrite(f, img)\n",
    "    return\n",
    "    \n",
    "#merge_bounding_box_images('b172', 'barkbeetles-of-guam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mturk_data_csv(bulletin, section):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    import glob\n",
    "    import pytesseract\n",
    "\n",
    "    try:\n",
    "        from PIL import Image\n",
    "    except ImportError:\n",
    "        import Image\n",
    "\n",
    "    prefix = 'https://github.com/aubreymoore/insects-of-guam-datamining/raw/master'\n",
    "\n",
    "    imagefiles = glob.glob('{}/{}/merged_images/*.jpg'.format(bulletin, section))\n",
    "    outfile = '{}/{}/mturk_data.csv'.format(bulletin, section)\n",
    "\n",
    "    with open(outfile, 'w+') as out:\n",
    "        out.write('image_url,text\\n')\n",
    "        for imagefile in imagefiles:\n",
    "            image_url = '{}/{}'.format(prefix, imagefile)\n",
    "\n",
    "            # Perform optical character recognition on the image\n",
    "            #text = pytesseract.image_to_string(Image.open(fn)).encode('utf-8')    \n",
    "\n",
    "            print('performing optical character recognition on {}'.format(imagefile))\n",
    "            text = pytesseract.image_to_string(Image.open(imagefile))\n",
    "\n",
    "            # Remove double quotes and replace line feeds with <br>\n",
    "            text = text.replace('\\n\\n', '\\n')\n",
    "            text = text.replace('\"', '').replace('\\n', '<br>')\n",
    "\n",
    "            # Separate collection records into individual lines of text\n",
    "            text = text.replace(';', '<br>')\n",
    "\n",
    "            # write record\n",
    "            out.write('{},\"{}\"\\n'.format(image_url, text))  \n",
    "            \n",
    "    return\n",
    "\n",
    "#make_mturk_data_csv('b172', 'barkbeetles-of-guam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aubrey/insects-of-guam-test/b172\n",
      "dragonflies-of-guam directory already exists.\n",
      "thrips-of-guam directory already exists.\n",
      "cercopidae-of-guam directory already exists.\n",
      "membracidae-of-guam directory already exists.\n",
      "psyllidae-from-guam directory already exists.\n",
      "aphidae-and-aleurodidae-of-guam directory already exists.\n",
      "neuropteroid-insects-from-guam directory already exists.\n",
      "butterflies-of-guam directory already exists.\n",
      "sphingidae-of-guam directory already exists.\n",
      "staphylinidae-of-guam directory already exists.\n",
      "rhipiceridae-of-guam directory already exists.\n",
      "ciidae-of-guam directory already exists.\n",
      "elaterid-and-eucnemid-beetles-of-guam directory already exists.\n",
      "coleoptera-heteromera-from-guam directory already exists.\n",
      "new-longicorn-beetles-from-guam-cerambycidae directory already exists.\n",
      "anthribidae-of-guam directory already exists.\n",
      "curculionidae-of-guam directory already exists.\n",
      "barkbeetles-of-guam directory already exists.\n",
      "miscellaneous-families-of-guam-coleoptera directory already exists.\n",
      "stylopidae-of-guam directory already exists.\n",
      "formicidae-of-guam directory already exists.\n",
      "wasps-of-guam directory already exists.\n",
      "bees-of-guam directory already exists.\n",
      "halictine-bees-from-rota-island directory already exists.\n",
      "tipulidae-of-guam directory already exists.\n",
      "culicidae-of-guam directory already exists.\n",
      "trypetidae-otitidae-helomyzidae-and-clusiidae-of-guam-diptera directory already exists.\n",
      "/home/aubrey/insects-of-guam-test\n"
     ]
    }
   ],
   "source": [
    "bulletin = 'b172'\n",
    "create_file_structure(bulletin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point the directory structure should look something like this:\n",
    "\n",
    "    b172\n",
    "        anthribidae-of-guam\n",
    "            anthribidae-of-guam.pdf\n",
    "            anthribidae-of-guam-0.jpg\n",
    "            anthribidae-of-guam-1.jpg\n",
    "            ...\n",
    "        formicidae-of-guam\n",
    "            formicidae-of-guam.pdf\n",
    "            formicidae-of-guam-0.jpg\n",
    "            formicidae-of-guam-1.jpg\n",
    "            ...\n",
    "            \n",
    "The PDF contains the whole section.\n",
    "There is JPG file for each page in the section.\n",
    "\n",
    "The next step is to use CVAT to record coordinates of bounding boxes which determine the position of species\n",
    "sections in the JPGs.  The resulting XML file can be downloaded into the section directory.\n",
    "\n",
    "Then, rerun this notebook, commit changes to the git repo, and push to github."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dragonflies-of-guam\n",
      "bb_xml_path_exists: True\n",
      "bb_csv_path_exists: True\n",
      "\n",
      "thrips-of-guam\n",
      "bb_xml_path_exists: True\n",
      "bb_csv_path_exists: True\n",
      "\n",
      "cercopidae-of-guam\n",
      "bb_xml_path_exists: True\n",
      "bb_csv_path_exists: True\n",
      "\n",
      "membracidae-of-guam\n",
      "bb_xml_path_exists: True\n",
      "bb_csv_path_exists: False\n",
      "Making bb table for membracidae-of-guam\n",
      "Extracting bounding box images.\n",
      "b172/membracidae-of-guam/bounding_box_images/Leptocentrus-taurus-0.jpg\n",
      "Merging bounding box images.\n",
      "species_names:           species_name\n",
      "0  Leptocentrus taurus\n",
      "Leptocentrus taurus\n",
      "                    bb_image\n",
      "0  Leptocentrus-taurus-0.jpg\n",
      "\n",
      "rowcount: 1\n",
      "f: b172/membracidae-of-guam/bounding_box_images/Leptocentrus-taurus-0.jpg\n",
      "Making mturk data csv.\n",
      "performing optical character recognition on b172/membracidae-of-guam/merged_images/Leptocentrus taurus.jpg\n",
      "\n",
      "psyllidae-from-guam\n",
      "bb_xml_path_exists: True\n",
      "bb_csv_path_exists: True\n",
      "\n",
      "aphidae-and-aleurodidae-of-guam\n",
      "bb_xml_path_exists: True\n",
      "bb_csv_path_exists: True\n",
      "\n",
      "neuropteroid-insects-from-guam\n",
      "bb_xml_path_exists: False\n",
      "bb_csv_path_exists: False\n",
      "\n",
      "butterflies-of-guam\n",
      "bb_xml_path_exists: False\n",
      "bb_csv_path_exists: False\n",
      "\n",
      "sphingidae-of-guam\n",
      "bb_xml_path_exists: False\n",
      "bb_csv_path_exists: False\n",
      "\n",
      "staphylinidae-of-guam\n",
      "bb_xml_path_exists: False\n",
      "bb_csv_path_exists: False\n",
      "\n",
      "rhipiceridae-of-guam\n",
      "bb_xml_path_exists: False\n",
      "bb_csv_path_exists: False\n",
      "\n",
      "ciidae-of-guam\n",
      "bb_xml_path_exists: False\n",
      "bb_csv_path_exists: False\n",
      "\n",
      "elaterid-and-eucnemid-beetles-of-guam\n",
      "bb_xml_path_exists: False\n",
      "bb_csv_path_exists: False\n",
      "\n",
      "coleoptera-heteromera-from-guam\n",
      "bb_xml_path_exists: False\n",
      "bb_csv_path_exists: False\n",
      "\n",
      "new-longicorn-beetles-from-guam-cerambycidae\n",
      "bb_xml_path_exists: False\n",
      "bb_csv_path_exists: False\n",
      "\n",
      "anthribidae-of-guam\n",
      "bb_xml_path_exists: True\n",
      "bb_csv_path_exists: True\n",
      "\n",
      "curculionidae-of-guam\n",
      "bb_xml_path_exists: False\n",
      "bb_csv_path_exists: False\n",
      "\n",
      "barkbeetles-of-guam\n",
      "bb_xml_path_exists: True\n",
      "bb_csv_path_exists: True\n",
      "\n",
      "miscellaneous-families-of-guam-coleoptera\n",
      "bb_xml_path_exists: False\n",
      "bb_csv_path_exists: False\n",
      "\n",
      "stylopidae-of-guam\n",
      "bb_xml_path_exists: False\n",
      "bb_csv_path_exists: False\n",
      "\n",
      "formicidae-of-guam\n",
      "bb_xml_path_exists: False\n",
      "bb_csv_path_exists: False\n",
      "\n",
      "wasps-of-guam\n",
      "bb_xml_path_exists: False\n",
      "bb_csv_path_exists: False\n",
      "\n",
      "bees-of-guam\n",
      "bb_xml_path_exists: True\n",
      "bb_csv_path_exists: True\n",
      "\n",
      "halictine-bees-from-rota-island\n",
      "bb_xml_path_exists: False\n",
      "bb_csv_path_exists: False\n",
      "\n",
      "tipulidae-of-guam\n",
      "bb_xml_path_exists: False\n",
      "bb_csv_path_exists: False\n",
      "\n",
      "culicidae-of-guam\n",
      "bb_xml_path_exists: False\n",
      "bb_csv_path_exists: False\n",
      "\n",
      "trypetidae-otitidae-helomyzidae-and-clusiidae-of-guam-diptera\n",
      "bb_xml_path_exists: False\n",
      "bb_csv_path_exists: False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "f = '{}/{}.csv'.format(bulletin, bulletin)\n",
    "df = pd.read_csv(f)\n",
    "for section in df.slug.values:\n",
    "    print(section)\n",
    "    bb_xml_path = '{}/{}/{}.xml'.format(bulletin, section, section)\n",
    "    bb_xml_path_exists = os.path.exists(bb_xml_path)\n",
    "    print('bb_xml_path_exists: {}'.format(bb_xml_path_exists))\n",
    "    bb_csv_path = '{}/{}/bounding_boxes.csv'.format(bulletin, section)\n",
    "    bb_csv_path_exists = os.path.exists(bb_csv_path)\n",
    "    print('bb_csv_path_exists: {}'.format(bb_csv_path_exists))\n",
    "    \n",
    "    if bb_xml_path_exists and not bb_csv_path_exists:\n",
    "        print('Making bb table for {}'.format(section))\n",
    "        make_bounding_box_table(bulletin, section)\n",
    "        \n",
    "        print('Extracting bounding box images.')\n",
    "        extract_bounding_box_images(bulletin, section)\n",
    "        \n",
    "        print('Merging bounding box images.')\n",
    "        merge_bounding_box_images(bulletin, section)\n",
    "        \n",
    "        print('Making mturk data csv.')\n",
    "        make_mturk_data_csv(bulletin, section)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
